# -*- coding: utf-8 -*-
"""Intro_to_Data_Augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qPhipwQe73nmHYYaHbCRL41b4qTAMGdx

# Introduction to data augmentation

## Overview

In this project we will work on augmenting our datasets, more specifically, our image dataset. We will do this by applying random, but realistic, transformations, such as rotation, saturation, greyscale, etc.


W will learn how to apply data augmentation in two ways:

- Use the Keras preprocessing layers, such as `tf.keras.layers.Resizing`, `tf.keras.layers.Rescaling`, `tf.keras.layers.RandomFlip`, and `tf.keras.layers.RandomRotation`.
- Use the `tf.image` methods, such as `tf.image.flip_left_right`, `tf.image.rgb_to_grayscale`, `tf.image.adjust_brightness`, `tf.image.central_crop`, and `tf.image.stateless_random*`.

## Setup

This project uses the [tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers) dataset, which contains over 3,600 images of flowers. These imagess range in quality, colour, size, etc.

If you are noticing a trend, the TensorFlow datasets are well curated (less time cleaning) and super easy to load and play with.
"""

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds

from tensorflow.keras import layers

(train_ds, val_ds, test_ds), metadata = tfds.load(
    'tf_flowers',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)

"""We will now see how many classes there are in the dataset, and then we will pull out an image for visual aids."""

num_classes = metadata.features['label'].num_classes
print(num_classes)

get_label_name = metadata.features['label'].int2str

image, label = next(iter(train_ds))
_ = plt.imshow(image)
_ = plt.title(get_label_name(label))

"""## Use Keras preprocessing layers

### Resizing and rescaling

We can use Keras preprocessing layers to perform two key operations:

- `tf.keras.layers.Resizing`: Resizes images to a consistent shape
- `tv.keras.layers.Rescaling`: Rescales the values of the pixels (0,1)

We will apply these transformations and then visualize the results in the following code:

<br>

---

*Note*:
- The rescaling layer below will standardizes the pixel values to the standard `[0, 1]` range. 
 - If instead we wanted it to be `[-1, 1]`, yweou would use `tf.keras.layers.Rescaling(1./127.5, offset=-1)`.
"""

IMG_SIZE = 180

resize_and_rescale = tf.keras.Sequential([
  layers.Resizing(IMG_SIZE, IMG_SIZE),
  layers.Rescaling(1./255)
])

result = resize_and_rescale(image)
_ = plt.imshow(result)

"""We can verify that our transformation worked properly by checking the pixel valuess fall between the `[0, 1]` range that we used."""

print("Min and max pixel values:", result.numpy().min(), result.numpy().max())

"""### Data augmentation

We will use the Keras preprocessing layers again, but this time we will call two different layers:

- `tf.keras.layers.RandomFlip`: Randomly flip the image on the horizontal or vertical axis
-`ts.keras.layers.RandomRotation`: Randomly rotate the image in 90 degree increments

<br>

---

Note: There are a variety of preprocessing layers you can use for data augmentation including `tf.keras.layers.RandomContrast`, `tf.keras.layers.RandomCrop`, `tf.keras.layers.RandomZoom`, and others.

Let's create a few preprocessing layers and apply them repeatedly to the same image.
"""

data_augmentation = tf.keras.Sequential([
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),
])

# Add the image to a batch.
image = tf.cast(tf.expand_dims(image, 0), tf.float32)

plt.figure(figsize=(10, 10))
for i in range(9):
  augmented_image = data_augmentation(image)
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(augmented_image[0])
  plt.axis("off")

"""### Two options to use the Keras preprocessing layers

When we are applying these different preprocessing layers, we have two main options, each with their own pros and cons.

- Integrate these layers to your model
- Apply these layers to your data

#### Option 1: Make the preprocessing layers part of your model
"""

model = tf.keras.Sequential([
  # Add the preprocessing layers we created earlier.
  resize_and_rescale,
  data_augmentation,
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  # Rest of our model.
])

"""Key Takeaways: 

- Our data augmentation steps will be integrated to the model, and will benefit for the accelerated processing of the GPU.

- When we export our model with `model.save`, the augmentation layers we added to this file, saving you time for needing to apply these layers saperately.

- Preprocessing could potentially bottleneck the model fit time if not properly tuned

- You must input raw images, if they have already been augmented, you will have a duplication of efforts.

<br>

#### Option 2: Apply the preprocessing layers to your dataset
"""

aug_ds = train_ds.map(
  lambda x, y: (resize_and_rescale(x, training=True), y))

"""Key Takeaways:

- Our data augmentation will happen separately, meaning we can run the preprocessing and the training of the batched data simultaneiously, by using `Dataset.prefetch`

- Our preprocessing will not be saved when we use the normal `Model.save`, meaning we will need to attach these layers to our model, or have them run specifically on the server/client side.

### Apply the preprocessing layers to the datasets

We will now configure our training, validation and test sets with our keras preprocessing layers we created earlier. 

*(Note: Data augmentation should only be applied to the training set)*

We will also use `AUTOTUNE` to optimize our preprocessing, training and testing.
"""

batch_size = 32
AUTOTUNE = tf.data.AUTOTUNE

def prepare(ds, shuffle=False, augment=False):
  # Resize and rescale all datasets.
  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), 
              num_parallel_calls=AUTOTUNE)

  if shuffle:
    ds = ds.shuffle(1000)

  # Batch all datasets.
  ds = ds.batch(batch_size)

  # Use data augmentation only on the training set.
  if augment:
    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), 
                num_parallel_calls=AUTOTUNE)

  # Use buffered prefetching on all datasets.
  return ds.prefetch(buffer_size=AUTOTUNE)

train_ds = prepare(train_ds, shuffle=True, augment=True)
val_ds = prepare(val_ds)
test_ds = prepare(test_ds)

"""### Train a model

We will now train the model using the datasets we just created. 


The Sequential model consists of three convolution blocks containing:

- `tf.keras.layers.Conv2D`: Input layer
 - `tf.keras.layers.MaxPooling2D`: Output layer

Finishing with:

- `tf.keras.layers.Dense`: A fully-connected layer with 128 units, activated by `'relu'` function

<br>

---

<br>

We will also apply our `Adam` optimizer, `losses`, and `accuracy` as our performance metric.

And then train the model for 5 epochs
"""

model = tf.keras.Sequential([
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=5
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

loss, acc = model.evaluate(test_ds)
print("Accuracy", acc)

"""### Custom data augmentation

We can also create our own custom data augmentation layers.

We will use two key methods here:

- `tf.keras.layers.Lambda`
- `subclasssing`


Both approaches will randomly invert the colors in an image, according to some probability.
"""

def random_invert_img(x, p=0.5):
  if  tf.random.uniform([]) < p:
    x = (255-x)
  else:
    x
  return x

def random_invert(factor=0.5):
  return layers.Lambda(lambda x: random_invert_img(x, factor))

random_invert = random_invert()

plt.figure(figsize=(10, 10))
for i in range(9):
  augmented_image = random_invert(image)
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(augmented_image[0].numpy().astype("uint8"))
  plt.axis("off")

"""We can now use `subclassing` to create a custom layer:"""

class RandomInvert(layers.Layer):
  def __init__(self, factor=0.5, **kwargs):
    super().__init__(**kwargs)
    self.factor = factor

  def call(self, x):
    return random_invert_img(x)

_ = plt.imshow(RandomInvert()(image)[0])

"""## Using tf.image

The keras layers we used are easy and convenient, but we may need finer control for our use cases. This is where `tf.data` and `tf.image` come to the rescue, by allowing us to build custom pipelines or layers. 

<br> 

---

<br>

We will import and retrieve a working image again, since we have applied augmentations to our previous sets.
"""

(train_ds, val_ds, test_ds), metadata = tfds.load(
    'tf_flowers',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)

image, label = next(iter(train_ds))
_ = plt.imshow(image)
_ = plt.title(get_label_name(label))

"""We will use the following code to set up an easy way for us to see our augmentations."""

def visualize(original, augmented):
  fig = plt.figure()
  plt.subplot(1,2,1)
  plt.title('Original image')
  plt.imshow(original)

  plt.subplot(1,2,2)
  plt.title('Augmented image')
  plt.imshow(augmented)

"""### Data augmentation

#### Flip an image

We can flip an image either vertically or horizontally with `tf.image.flip_left_right`:
"""

flipped = tf.image.flip_left_right(image)
visualize(image, flipped)

"""#### Grayscale an image

We can grayscale an image with `tf.image.rgb_to_grayscale`:
"""

grayscaled = tf.image.rgb_to_grayscale(image)
visualize(image, tf.squeeze(grayscaled))
_ = plt.colorbar()

"""#### Saturate an image

We can saturate an image with `tf.image.adjust_saturation` by providing a saturation factor:
"""

saturated = tf.image.adjust_saturation(image, 3)
visualize(image, saturated)

"""#### Change image brightness

Change the brightness of image with `tf.image.adjust_brightness`
"""

bright = tf.image.adjust_brightness(image, 0.4)
visualize(image, bright)

"""#### Center crop an image

Crop the image from center up to the image part you desire using `tf.image.central_crop`:
"""

cropped = tf.image.central_crop(image, central_fraction=0.5)
visualize(image, cropped)

"""#### Rotate an image

Rotate an image by 90 degrees with `tf.image.rot90`:
"""

rotated = tf.image.rot90(image)
visualize(image, rotated)

"""### Random transformations

Applying random transformations to the images can further help generalize and expand the dataset. The current `tf.image` API provides eight such random image operations (ops):

*   [`tf.image.stateless_random_brightness`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_brightness)
*   [`tf.image.stateless_random_contrast`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_contrast)
*   [`tf.image.stateless_random_crop`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_crop)
*   [`tf.image.stateless_random_flip_left_right`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_flip_left_right)
*   [`tf.image.stateless_random_flip_up_down`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_flip_up_down)
*   [`tf.image.stateless_random_hue`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_hue)
*   [`tf.image.stateless_random_jpeg_quality`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_jpeg_quality)
*   [`tf.image.stateless_random_saturation`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_saturation)

#### Randomly change image brightness

We will now change the brightness of the images in a random manner. We will use `stateless_random_brightness` by providing a brightnesss factor and `seed`. 

- The brightness will be chosen randomly chosen based on the range we provide with `-max_delta`, or `max_delta`
"""

for i in range(3):
  seed = (i, 0)
  stateless_random_brightness = tf.image.stateless_random_brightness(
      image, max_delta=0.95, seed=seed)
  visualize(image, stateless_random_brightness)

"""#### Randomly change image contrast

We can randomly change the contrast of an image with `stateless_random_contrast`. Once again we will provide and range (`upper`, `lower`) and seed as well.
"""

for i in range(3):
  seed = (i, 0)  # tuple of size (2,)
  stateless_random_contrast = tf.image.stateless_random_contrast(
      image, lower=0.1, upper=0.9, seed=seed)
  visualize(image, stateless_random_contrast)

"""#### Randomly crop an image

We can also use `tr.image.sstateless_random_crop` to apply a random cropping to the image. We will provide a size and seed for this operation.
"""

for i in range(3):
  seed = (i, 0)  # tuple of size (2,)
  stateless_random_crop = tf.image.stateless_random_crop(
      image, size=[210, 300, 3], seed=seed)
  visualize(image, stateless_random_crop)

"""### Apply augmentation to a dataset

We will start with downloading the dataset again to ensure we have unmodified images. We will also define a utility function to help us in resizing and scalling. 

*Note: This function will help us by making all of our images the same size, and scaling for more optimal procesing.*
"""

(train_datasets, val_ds, test_ds), metadata = tfds.load(
    'tf_flowers',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)

def resize_and_rescale(image, label):
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
  image = (image / 255.0)
  return image, label

"""We will also define an *augment* function. This function will be used to apply the different operations we choose to the entire dataset."""

def augment(image_label, seed):
  image, label = image_label
  image, label = resize_and_rescale(image, label)
  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)
  # Make a new seed.
  new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]
  # Random crop back to the original size.
  image = tf.image.stateless_random_crop(
      image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)
  # Random brightness.
  image = tf.image.stateless_random_brightness(
      image, max_delta=0.5, seed=new_seed)
  image = tf.clip_by_value(image, 0, 1)
  return image, label

"""#### Option 1: Using tf.data.experimental.Counter

We are going to use the `tf.data.experimental.Counter` object to help us apply our random seeds to the images. We will create this counter to associate a value to each image, this value will then be used to a unique value in the shape of `(2,)`.

This counter will then be joined with the training dataset (our images) and compressed together with `Data.zip`.
"""

counter = tf.data.experimental.Counter()
train_ds = tf.data.Dataset.zip((train_datasets, (counter, counter)))

"""We will now  map our `augment` function to the training dataset:"""

train_ds = (
    train_ds
    .shuffle(1000)
    .map(augment, num_parallel_calls=AUTOTUNE)
    .batch(batch_size)
    .prefetch(AUTOTUNE)
)

val_ds = (
    val_ds
    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)
    .batch(batch_size)
    .prefetch(AUTOTUNE)
)

test_ds = (
    test_ds
    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)
    .batch(batch_size)
    .prefetch(AUTOTUNE)
)

"""#### Option 2: Using tf.random.Generator

We can also use the `tf.random.Generator` with an initial seed value instead of the previous example. 

When we call the `make`seeds` function will return a new value each time, in comparison to the previous example, which returns the same value for each image.

To do this we will create a wrapper to:

- Call the `make_seeds` function
- Pass the newly generated `seed` value into the `augment` function

- Define a wrapper function that: 1) calls the `make_seeds` function; and 2) passes the newly generated `seed` value into the `augment` function for random transformations.
"""

# Create a generator.
rng = tf.random.Generator.from_seed(123, alg='philox')

# Create a wrapper function for updating seeds.
def f(x, y):
  seed = rng.make_seeds(2)[0]
  image, label = augment((x, y), seed)
  return image, label

"""We will now map the wrapper function, which we will call `f`, to the training dataset. Afterwardss, we will `resize_and_rescale` function to the validation and test datasets."""

train_ds = (
    train_datasets
    .shuffle(1000)
    .map(f, num_parallel_calls=AUTOTUNE)
    .batch(batch_size)
    .prefetch(AUTOTUNE)
)

val_ds = (
    val_ds
    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)
    .batch(batch_size)
    .prefetch(AUTOTUNE)
)

test_ds = (
    test_ds
    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)
    .batch(batch_size)
    .prefetch(AUTOTUNE)
)

"""## Next steps

As we can see here, data augmentation is easy and can be applied to greatly increase your datasets in new and unique ways.

I would highly recommend playing around with these functions on your own images.
"""